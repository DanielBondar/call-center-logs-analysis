 # Проект по анализу разговоров пользователей с операторами call-центра разбивается на
## 2 задачи - Кластеризация и Анализ тональности.

### Кластеризация.

### Цель кластеризации - определить основные тематики диалогов с операторами.

### Реализация:

Весь код программы написан на языке Python.
Используемые библиотеки: nltk, rnnmorph, genism, sklear.

Сначала мы производим чистку текста от служебной информации, оставшейся после распознавания речи, чтобы избавиться от слов, которые не повлияют на корректную работу нашей программы и объединяем речь оператора и клиента. После этого происходит нормализация текста, т.е. замена различных форм слов на начальную форму (библиотека rnnmorph), большую букву на маленькую, обобщение слов - псевдо токенизация именованных сущностей (страна, города России, зарубежные города, имена, станции метро), например, замена слов Новосибирск, Пермь, на слово город. И проверка текста на ошибки перевода из аудио в текстовый формат, которая производилась вручную для самых часто встречаемых ошибках. Используя библиотеку nltk, мы удаляем предлоги, союз и другие “ненужные” стоп-слова.
Далее происходит выделение признаков текста для кластеризации. Мы использовали два метода – tf-idf и doc2vec.

После того, как мы получили массив чисел, происходит сам процесс кластеризация методом K-means, который позволяет нам получить список номеров кластеров, по которым мы как раз и сопоставляем наши диалоги с метками кластеров.
Изначально мы знаем лишь границы, в которых меняется число тем разговоров. Для нашей задачи оно меняется от 3 до 10. Опытным путём выявлено, что лучше всего текст разбивается на 5 тем.

После этого происходит визуализация полученного результата с помощью пакета MDS библиотеки sklearn. Мы переходим от n-мерного пространства векторов к 2-мерному с сохранением расстояния.
Для выбора ключевых слов в темах мы рассматривали произвольный текст и в нем - 5 слов, у которых наибольший балл tf-idf.

### Анализ тональностей.

### Цели анализа тональностей - оценка диалога на основе реальных оценок пользователей

### Реализация:

Весь код программы написан на языке Python.
Использованные библиотеки: nltk, gensim, scipy, rnnmorph, sklearn.

Анализ текста происходит аналогично анализу в задаче выше, но реализуется только один метод выделение признаков – doc2vec.
Далее требуется выбрать метод, который будет лучше всего работать на несбалансированной выборке, т.е. когда число элементов классов сильно различны между собой. В нашем случае в выборке присутствуют 175 положительных и 27 отрицательных отзывов о работе call-центра.

Мы рассмотрели три метода работы с несбалансированными выборками: метод Логистической регрессии со сбалансированными весами классов, метод SVC со сбалансированными весами классов и метод Ridge с коэффициентом регуляризации 3. Для описания погрешности используем F-меру с параметром 1.
Чтобы улучшить работу программы мы пользуемся кросс-валидация, разбивая начальную выборку на 4 части. Алгоритм stratify помогает в выборе частей разбиения.  

